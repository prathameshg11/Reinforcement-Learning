{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d392d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46c458ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: g-dbus-error-quark: The name org.freedesktop.secrets was not provided by any .service files (2)\u001b[0m\n",
      "Collecting box2d-py\n",
      "  Using cached box2d-py-2.3.8.tar.gz (374 kB)\n",
      "Building wheels for collected packages: box2d-py\n",
      "  Building wheel for box2d-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for box2d-py: filename=box2d_py-2.3.8-cp310-cp310-linux_x86_64.whl size=2543719 sha256=0da2c3c3bf1c1d70af41c5c238f99b58bb9fc96ed89fe3e0ce754c277f25001d\n",
      "  Stored in directory: /home/prathamesh/.cache/pip/wheels/47/01/d2/6a780da77ccb98b1d2facdd520a8d10838a03b590f6f8d50c0\n",
      "Successfully built box2d-py\n",
      "Installing collected packages: box2d-py\n",
      "Successfully installed box2d-py-2.3.8\n"
     ]
    }
   ],
   "source": [
    "!pip install box2d-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167fde82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prathamesh/.local/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "states = env.observation_space.shape[0]\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee5268b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e4d0310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode :1, score : -460.93776727999364\n",
      "episode :2, score : -252.81374048663537\n",
      "episode :3, score : -615.9988531592777\n",
      "episode :4, score : -367.8110793204987\n",
      "episode :5, score : -355.7698572301502\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for i in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = random.choice([0,3])\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score +=reward\n",
    "    print(f\"episode :{i}, score : {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac15d799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "# from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28ec4574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(states, actions):\n",
    "    model = tensorflow.keras.Sequential()\n",
    "    model.add(Flatten(input_shape=(1, states)))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caeb2cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  build_model(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a91f311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 24)                216       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 24)                600       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 100       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 916\n",
      "Trainable params: 916\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b9b979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2131b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = BoltzmannQPolicy()\n",
    "    memory = SequentialMemory(limit=5000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy= policy, \n",
    "                   nb_actions = actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "525f1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = build_agent(model, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56e78db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 23:32:44.229652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-02 23:32:44.230072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-02 23:32:44.230270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-02 23:32:44.230538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-02 23:32:44.230769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-02 23:32:44.230951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2638 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2022-07-02 23:32:44.238616: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "dqn.compile(Adam(learning_rate=1e-3), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ad033d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100000 steps ...\n",
      "Interval 1 (0 steps performed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prathamesh/.local/lib/python3.10/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "    1/10000 [..............................] - ETA: 1:17:20 - reward: 0.6600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 10 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34/10000 [..............................] - ETA: 2:12 - reward: -1.2099"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 11 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 12 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 13 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 14 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 15 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 16 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 17 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 18 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 19 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 20 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 21 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 22 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 23 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 24 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 25 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 26 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 27 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 28 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 29 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 30 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "/home/prathamesh/.local/lib/python3.10/site-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 31 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 64s 6ms/step - reward: -0.5445\n",
      "47 episodes - episode_reward: -115.595 [-352.108, 133.593] - loss: 16.180 - mae: 13.509 - mean_q: 12.160\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 50s 5ms/step - reward: -0.0617\n",
      "14 episodes - episode_reward: -54.503 [-415.981, 160.992] - loss: 5.685 - mae: 25.210 - mean_q: 11.715\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 50s 5ms/step - reward: 0.0386\n",
      "18 episodes - episode_reward: 26.831 [-195.385, 228.713] - loss: 3.175 - mae: 17.086 - mean_q: 18.716\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 49s 5ms/step - reward: 0.0799\n",
      "14 episodes - episode_reward: 52.631 [-122.236, 178.713] - loss: 6.161 - mae: 24.317 - mean_q: 33.236\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 49s 5ms/step - reward: 0.1194\n",
      "14 episodes - episode_reward: 92.169 [-100.711, 222.549] - loss: 4.308 - mae: 25.773 - mean_q: 35.702\n",
      "\n",
      "Interval 6 (50000 steps performed)\n",
      "10000/10000 [==============================] - 49s 5ms/step - reward: 0.0530\n",
      "15 episodes - episode_reward: 28.952 [-270.149, 232.759] - loss: 3.787 - mae: 25.396 - mean_q: 35.910\n",
      "\n",
      "Interval 7 (60000 steps performed)\n",
      "10000/10000 [==============================] - 52s 5ms/step - reward: 0.0147\n",
      "19 episodes - episode_reward: 4.151 [-291.095, 203.002] - loss: 7.605 - mae: 29.691 - mean_q: 39.615\n",
      "\n",
      "Interval 8 (70000 steps performed)\n",
      "10000/10000 [==============================] - 50s 5ms/step - reward: 0.1044\n",
      "13 episodes - episode_reward: 82.627 [-71.793, 176.791] - loss: 4.120 - mae: 28.296 - mean_q: 40.057\n",
      "\n",
      "Interval 9 (80000 steps performed)\n",
      "10000/10000 [==============================] - 49s 5ms/step - reward: -0.0335\n",
      "28 episodes - episode_reward: -9.002 [-143.066, 160.648] - loss: 6.796 - mae: 35.412 - mean_q: 47.021\n",
      "\n",
      "Interval 10 (90000 steps performed)\n",
      "10000/10000 [==============================] - 54s 5ms/step - reward: 0.0095\n",
      "done, took 516.324 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f486c5e43d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=100000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b7a1d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 10 episodes ...\n",
      "Episode 1: reward: -151.746, steps: 91\n",
      "Episode 2: reward: -51.964, steps: 90\n",
      "Episode 3: reward: -194.612, steps: 72\n",
      "Episode 4: reward: -22.204, steps: 83\n",
      "Episode 5: reward: -41.580, steps: 1000\n",
      "Episode 6: reward: -80.376, steps: 1000\n",
      "Episode 7: reward: -33.986, steps: 1000\n",
      "Episode 8: reward: -57.930, steps: 1000\n",
      "Episode 9: reward: -70.126, steps: 1000\n",
      "Episode 10: reward: -41.802, steps: 1000\n",
      "-74.63271565346315\n"
     ]
    }
   ],
   "source": [
    "scores = dqn.test(env, nb_episodes=10, visualize=False)\n",
    "print(np.mean(scores.history['episode_reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a170aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: -53.698, steps: 1000\n",
      "Episode 2: reward: -84.517, steps: 1000\n",
      "Episode 3: reward: -144.101, steps: 73\n",
      "Episode 4: reward: 182.181, steps: 912\n",
      "Episode 5: reward: -22.920, steps: 1000\n"
     ]
    }
   ],
   "source": [
    "_ = dqn.test(env, nb_episodes=5, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f950cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
